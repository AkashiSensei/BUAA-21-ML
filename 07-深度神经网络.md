# 7.1 深度神经网络

## 什么是深度神经网络

对客观世界的认知是非线性、复杂的。

**深度神经网络**：模仿人类大脑的处理方式，通过多层（即“深度”）的神经元结构处理数据。

## 神经网络的发展史

见[[06-神经网络#神经网络的发展概述]]。

## 深度神经网络的应用

见[[06-神经网络#神经网络的应用]]。

# 7.2 卷积神经网络

## 卷积神经网络的特点

### 生物视觉皮层研究基础

#### 人脑视觉皮层的研究

人脑的视觉皮层由多个层次组成，每个层次负责处理不同的视觉信息。
- V1区域负责处理边缘检测，而更高层次的区域则负责识别更复杂的形状和对象。
- 层级结构：Retina (pixels) → Area V1（Edge detectors）→ Area V2（Primitive shape detectors）→ Area V4（Higher level visual abstraction）。

#### 猫视觉皮层神经元的研究

- 感受野通常是局部的，每个神经元只对视觉场景中的一小部分区域有反应。
- 相同的权重模式可以在视觉皮层的不同位置复制，以检测不同位置的相同特征。
- 神经元类型：
  - 简单细胞：响应光照方向；
  - 复杂细胞：响应光照方向和运动；
  - 超复杂细胞：响应端点的运动。
- 参考文献：HUBEL DH, WIESEL TN. Receptive fields, binocular interaction and functional architecture in the cat's visual cortex. J Physiol. 1962 Jan;160(1):106-54.

### 卷积神经网络的核心定义

卷积神经网络（Convolutional Neural Networks, CNN）：仿照生物的视觉感知机制，是一类包含卷积计算、具有深度结构的前馈神经网络。

### CNN的核心特点

#### CNN特点之一：局部感知

- 核心思想：每个隐藏层单元仅接收输入的局部区域信息，而非全部输入，大幅减少参数数量。
- 示例对比：
  - 输入大小1000×1000，10⁶个隐藏层单元，每个接收10×10输入：传统全连接需10⁸个参数，局部感知仅需10⁴个参数。
- 卷积运算：例如5×5大小的灰度图，使用3×3卷积核（Filter），偏置项（bias）为0，步长（Step-size）为1，得到3×3大小的输出（特征图）。
- 滑动窗口与步长：步长决定卷积核移动的间隔，步长=1时逐像素滑动，步长=2时每隔1个像素滑动。
- 边缘填充（padding）：解决卷积后特征图缩小、边缘信息参与计算次数少的问题，通过填充扩展输入边缘，使特征图尺寸保持或调整至目标大小。

#### CNN特点之二：权值共享

- 核心思想：不同位置的局部窗口使用相同的卷积核权重参数，进一步减少参数冗余，提升训练效率。
- 示例：5×5输入X与3×3卷积核W进行卷积时，所有局部窗口共用同一组W参数，输出3×3特征图Y。

#### CNN特点之三：多卷积核运算

- 核心思想：为充分提取各种特征，使用多个卷积核，每个卷积核学习不同特征（如边缘、纹理、形状等）。
- 通道（Channels）：特征图按通道叠加，输入通道数=卷积核深度，输出通道数=卷积核个数。
- 示例：对同一输入，不同卷积核可提取猫的耳朵、胡须等不同特征。

#### CNN特点之四：池化（Pooling）

- 别称：下采样（Subsampling）或汇聚层，对不同空间位置的特征值进行聚合统计。
- 常用操作：最大池化（Max Pooling）、平均池化（Mean Pooling）、随机池化（Stochastic Pooling）。
- 核心作用：
  - 降维，减少参数和计算量，防止过拟合；
  - 使模型对尺度、平移、旋转变化具有一定的不变性。
- 典型采样区域：2×2。

#### CNN特点之五：多层处理

- 特征进化：单层卷积及池化仅学到局部特征，层数越多，所学特征越全局，低级特征可组合形成更高级特征。
- 典型结构：由卷积层、汇聚层（池化）、全连接层交叉堆叠而成，趋向于小卷积、大深度。
- 结构组成：
  - 一个卷积块为连续M个卷积层和b个汇聚层（M通常为2～5，b为0或1）；
  - 一个卷积网络可堆叠N个连续卷积块，后续接K个全连接层（N取值1～100+，K一般为0～2）。

### 卷积操作示例

- 卷积计算式：$w \otimes x + b$，例如卷积核参数为[-1,1,1,-1]，偏置项（Bias）=1，计算得-1+1+1+1+1=2。
- 多通道示例：输入为R、G、B三通道图像，不同通道的卷积核分别提取对应通道的特征，最终融合输出。
- 参考链接：https://cs231n.github.io/convolutional-networks/

## 经典卷积神经网络结构
### LeNet5（1998）

- 地位：最早的卷积神经网络（CNN）之一。
- 核心结构与参数：
  - C1（卷积层）：输入32×32，卷积核5×5×6，输出28×28×6，可训练参数(5×5+1)×6；
  - S2（池化层）：输入28×28×6，采样区域2×2，输出14×14×6；
  - 后续层：卷积层、池化层、全连接层、高斯连接层依次堆叠。
- 性能：在MNIST 60,000训练集上的错误率为0.95%。
- 参考文献：LeCun Y, Bottou L, Bengio Y, et al. Gradient-based learning applied to document recognition[J]. Proceedings of the IEEE, 1998, 86(11): 2278-2324.

### AlexNet（2012）

- 地位：ILSVRC竞赛冠军，深度学习在图像领域的里程碑突破。
- 核心结构：共8层，前5层为卷积层，后3层为全连接层。
- 技术特点：因当时GPU内存限制，采用两块GPU并行计算，分为上下两部分结构。
- 关键创新：引入Dropout防止过拟合。
- 参考文献：Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural networks[J]. Advances in neural information processing systems, 2012, 25.

### Dropout（AlexNet关键技术）

- 定义：在深度学习网络训练过程中，按照一定概率将神经网络单元暂时从网络中丢弃，使每个小数据集训练不同的网络子集。
- 作用：防止过拟合，强迫神经元与随机挑选的其他神经元共同工作，消除减弱神经元节点间的联合适应性，增强泛化能力。

### VGG（2014）

- 地位：ILSVRC竞赛亚军，因结构规律、可移植性强被广泛应用。
- 核心结构：13层卷积层+3层全连接层。
- 特征图演变：224×224×3 → 224×224×64 → 112×112×128 → 56×56×256 → 28×28×512 → 14×14×512 → 7×7×512 → 1×1×4096 → 1×1×4096 → 1×1×1000。
- 参考文献：Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition[J]. arxiv preprint arxiv:1409.1556, 2014.

### 多层小卷积代替单层大卷积

- 核心原理：两层3×3卷积的感受野与一层5×5卷积一致，但参数量更少（3×3×2=18 < 5×5=25），减少约30%。
- 优势：更深的层数带来更多非线性变换，更好地拟合特征。

### ResNet（2015）

- 地位：ILSVRC竞赛冠军，解决深度网络梯度消失问题的核心模型。
- 核心特点：BottleNeck结构、残差结构（跳跃连接）。
- 性能：错误率3.57%。
- 不同深度版本：
  - ResNet-50（50层）：g=[3,4,6,3]；
  - ResNet-101（101层）：g=[3,4,23,8]；
  - ResNet-152（152层）：g=[3,8,36,3]。
- 核心创新：通过跳跃连接使梯度直接反向传播，缓解深度增加导致的梯度消失，支持构建更深神经网络，易收敛且不退化。

## 卷积神经网络的应用

### 应用分类：按处理数据的模态划分

#### 图像与视频模态

##### 视频模态：三维卷积

- 核心思想：卷积核增加一个维度的滑动，获取图片之间的关联信息，保存输入信号的时间信息。
- 三种处理方式对比：
  - (a) 对图像进行二维卷积；
  - (b) 用二维卷积处理多帧视频（多帧作为多通道），输出单张图像；
  - (c) 用三维卷积处理多帧视频，输出增加时间维度的特征图。
- 参考文献：Tran D, Bourdev L, Fergus R, et al. Learning spatiotemporal features with 3d convolutional networks[C]//Proceedings of the IEEE international conference on computer vision. 2015: 4489-4497.

##### 图像模态

- 图像分类：全连接层输出类别概率，LeNet-5、AlexNet等可直接应用。
- 目标检测：两个子任务（定位边界框与图像分类）：
  - 双阶段（Two-Stage）：例如Faster-RCNN，通过RPN模块生成候选框，再基于候选框分类和调整；
  - 单阶段（One-Stage）：例如SSD、YOLO，基于锚框（anchors）直接分类和调整边界框。
- 图像分割：按像素点分类，需将缩小的特征图上采样至原始大小，代表模型：UNet、Mask R-CNN。

#### 音频与文本模态

##### 一维卷积的应用

- 适用场景：更好处理序列数据（语音、文本、传感器数据等）。
- 核心特点：与二维、三维卷积本质一致，区别仅在于卷积核的滑动方式。
- 音频处理示例：语音情感识别，通过1D CNN提取音频特征后分类。
- 参考文献：Li Y, Baidoo C, Cai T, et al. Speech emotion recognition using 1d cnn with no attention[C]//2019 23rd international computer science and engineering conference (ICSEC). IEEE, 2019: 351-356.

##### 自然语言处理（NLP）应用

- 数据表示：矩阵每一行对应一个单词的向量。
- 处理流程：设置三种不同大小的滤波器（2、3、4行），每种两个，得到特征字典；通过max pooling生成单变量特征向量；拼接后经softmax输出。
- 替代方案：将一维音频数据转化为二维频谱图，使用二维卷积分析处理。
- 参考文献：Rakhlin A. Convolutional neural networks for sentence classification[J]. GitHub, 2016, 6: 25.

#### 点云模态

##### 点云数据特点

- 定义：三维坐标系统中的一组向量集合，每个点包含三维坐标，部分含颜色（RGB）或反射强度（Intensity）信息。
- 局限：无规范数据格式，不适用于普通卷积。

##### 点云处理方法：分层卷积

- Conv（常规卷积）：递归处理局部网格面片，逐步降低网格分辨率（4×4→3×3→2×2），同时增加通道数。
- X-Conv（点云专用卷积）：递归将邻域信息“投影”或“聚集”为更少代表点（9→5→2），使每个点获得更丰富信息。
- 网络结构：取最邻近的k个点→采样K个点→卷积下采样+卷积上采样。
- 参考文献：Li Y, Bu R, Sun M, et al. Pointcnn: Convolution on x-transformed points[J]. Advances in neural information processing systems, 2018, 31.

### 其他应用场景

- 自动驾驶：环境感知、障碍物检测、点云数据分析；
- 地形分析：城市规划等建设；
- 医学成像：手术规划等医学研究。

# 7.3 深度神经网络的训练策略

## 梯度消失问题

### 问题定义

隐藏层神经元定义：$neuro _{i}^{l}=\sigma(w_{i}^{l} x_{i}^{l}+b_{i}^{l})$

梯度定义：$\delta_{i}^{l}=\frac{\partial E}{\partial b_{i}^{l}}$，其中$\left\|\delta^{l}\right\|$表示$l$层的学习速度。

梯度消失/爆炸现象：在深度神经网络中，随着网络层数增加，梯度可能急剧减小（梯度消失）或急剧增大（梯度爆炸），导致模型难以训练。

### 起因

考虑每层只有一个神经元的多层神经网络，梯度传递满足链式法则：
$$\delta^{1} \leftarrow \delta^{2} \leftarrow \delta^{3} \leftarrow \delta^{4} \leftarrow \delta^{5} \leftarrow \delta^{6} \leftarrow \delta^{7} \leftarrow \delta^{8} \leftarrow \delta^{9} \leftarrow \delta^{10}$$

展开形式：
$$\delta^{1} = \delta^{2} \cdot w^{2} \cdot \sigma' = \delta^{3} \cdot w^{3} \cdot \sigma' \cdot w^{2} \cdot \sigma' = \cdots = \delta^{10} \cdot \prod_{l=2}^{10} (w^{l} \cdot \sigma')$$

- 当$\left\|w^{l} \cdot \sigma'\right\| < 1$时，梯度逐层衰减，导致浅层梯度趋近于0（梯度消失）；
- 当$\left\|w^{l} \cdot \sigma'\right\| > 1$时，梯度逐层放大，导致浅层梯度趋近于无穷大（梯度爆炸）。

### 解决策略

#### 线性整流激活函数（Rectified Linear Units, ReLU）

- 函数定义：$f(x)=\max(0, x)$
- 优势：
  1. 避免梯度消失问题：导数为0或1，梯度传递过程中不易衰减；
  2. 简化计算过程；
  3. 有利于训练稀疏网络。

#### 残差神经网络（Residual neural network, ResNet）

- 基本思想：使用残差模块（Residual block），在输入和输出之间加入“捷径”连接（shortcut connection）。
- 核心公式：
  $$\mathcal{F}(x)=\mathcal{H}(x)-x$$
  $$y=\mathcal{H}(x)=x+\mathcal{F}(x)$$
- 梯度传递：
  $$x^{L}=x^{l}+\sum_{i=l}^{L-1} \mathcal{F}\left(x^{i}\right)$$
  $$\frac{\partial E}{\partial x^{l}}=\frac{\partial E}{\partial x^{L}}\left(1+\frac{\partial \sum_{i=l}^{L-1} \mathcal{F}\left(x^{i}\right)}{\partial x^{l}}\right)$$
- 优势：梯度能够通过残差模块直接反向传播，更容易从输出层传播回输入层，减少梯度消失风险，可构造更深神经网络，易收敛且不退化。

## 优化问题

### 核心挑战

深度神经网络的优化是高维空间的非凸优化问题，传统优化算法容易陷入局部极小值、鞍点或平坦底部，导致模型性能不佳。

### 梯度下降算法

| 名称 | 计算公式 | 更新样本量 | 特点 |
| --- | --- | --- | --- |
| 随机梯度下降（Stochastic gradient descent, SGD） | $w^{(\tau+1)} = w^{(\tau)} - \eta \cdot \Delta E(x_i; w^{(\tau)})$ | 单个样本 | 1. 引起梯度震荡；2. 相似样本存在冗余计算 |
| 批梯度下降（Batch gradient descent） | $w^{(\tau+1)} = w^{(\tau)} - \eta \cdot \frac{1}{N} \sum_{i=1}^{N} \Delta E(x_i; w^{(\tau)})$ | 所有样本 | 1. 计算量大；2. 易陷入局部极小值 |
| 小批量梯度下降（Mini-Batch gradient descent） | $w^{(\tau+1)} = w^{(\tau)} - \eta \cdot \frac{1}{B} \sum_{i=1}^{B} \Delta E(x_i; w^{(\tau)})$ | 部分样本（批量大小B） | 1. 计算更高效；2. 收敛更稳定；3. 样本使用更灵活 |

### 可变学习率优化算法

#### Adagrad

- 核心思想：对稀疏参数进行大幅更新，对频繁参数进行小幅更新。
- 学习率公式：$\eta^{\tau}=\frac{\eta^{0}}{\sqrt{\sum_{t=1}^{\tau} \Delta E^{2}(w^{(t)})+\epsilon}}$
- 权重更新：$w^{(\tau+1)}=w^{(\tau)}-\eta^{\tau} \Delta E\left(w^{(\tau)}\right)$
- 特点：适合处理稀疏数据。

#### RMSprop

- 核心思想：引入梯度平方的移动平均调整每个参数的学习率，解决Adagrad学习率衰减问题。
- 梯度平方移动平均：$g^{(\tau)}=\alpha g^{(\tau-1)}+(1-\alpha) \cdot \left[\nabla_{w} E^{(\tau)}\right]^{2}$
- 权重更新：$w^{(\tau+1)}=w^{(\tau)}-\frac{\eta^{0}}{\sqrt{g^{(\tau)}+\epsilon}} \Delta E(w^{(\tau)})$
- 特点：学习率更稳定，避免后期更新停滞。

#### Adadelta

- 核心思想：使用前一次的梯度开方代替固定学习率，无需设置默认学习率。
- 权重更新：$w^{(\tau+1)}=w^{(\tau)}-\frac{\sqrt{\Delta w^{(\tau-1)}+\epsilon}}{\sqrt{g^{(\tau)}+\epsilon}} \Delta E(w^{(\tau)})$
- 特点：减少超参数调整需求。

### 动量优化算法

#### 动量SGD（Momentum SGD）

- 核心思想：引入动量（momentum）抑制梯度震荡，模拟物理中的惯性，加速收敛。
- 动量更新：$g^{(\tau)}=\alpha g^{(\tau-1)}+\eta \nabla_{w} E^{(\tau)}$，其中$g^{(0)}=\nabla_{w} E^{(0)}$
- 权重更新：$w^{(\tau+1)}=w^{(\tau)}-g^{(\tau)}$
- 特点：减少局部极值和鞍点的影响，收敛更平稳。

#### Nesterov梯度（NAG）

- 核心思想：具有预测性，先按前一时刻动量移动，再计算梯度。
- 预更新：$w^{(\tau)}_{pre}=w^{(\tau)}+\beta g^{(\tau-1)}$
- 梯度计算：$g^{(\tau)}=\alpha g^{(\tau-1)}+\eta \nabla_{w} E(w^{(\tau)}_{pre})$
- 权重更新：$w^{(\tau+1)}=w^{(\tau)}-g^{(\tau)}$
- 特点：对优化方向有预判，收敛速度更快。

#### Adam

- 核心思想：Adaptive + momentum，结合动量和自适应学习率。
- 步骤1：计算一阶矩（动量）和二阶矩（梯度平方移动平均）：
  $$m^{(\tau)}=\alpha \cdot m^{(\tau-1)}+(1-\alpha) \cdot \nabla_{w} E^{(\tau)}$$
  $$n^{(\tau)}=\beta \cdot n^{(\tau-1)}+(1-\beta) \cdot \left[\nabla_{w} E^{(\tau)}\right]^{2}$$
- 步骤2：修正偏差：
  $$\hat{m}^{(\tau)}=\frac{m^{(\tau)}}{1-\alpha^{\tau}}$$
  $$\hat{n}^{(\tau)}=\frac{n^{(\tau)}}{1-\beta^{\tau}}$$
- 步骤3：权重更新：
  $$w^{(\tau+1)}=w^{(\tau)}-\frac{\eta}{\sqrt{\hat{n}^{(\tau)}}+\epsilon} \hat{m}^{(\tau)}$$
- 特点：最常用的优化算法，收敛快且稳定。

### 其他优化方案

1. 正则化：$\ell_{1}$ 和 $\ell_{2}$ 正则化（详见课程4.2、4.3）；
2. Dropout（详见7.2）；
3. Early stop：当测试误差不再下降或开始上升时停止训练，避免过拟合；
4. 数据增强：通过图像翻转、裁剪、加噪等方式扩充训练数据，提升泛化能力；
5. Batch Normalization：独立计算每个维度的均值和方差，标准化输入，稳定反向传播梯度，加速训练收敛：
  $$\hat{x}^{(k)}=\frac{x^{(k)}-E\left[x^{(k)}\right]}{\sqrt{Var\left[x^{(k)}\right]+\epsilon}}$$

# 7.4 递归神经网络

## 循环神经网络（Recurrent Neural Network, RNN）

### 核心应用场景

- 序列问题：处理时间序列数据（如气象预测、股票预测）、自然语言处理（如机器翻译、文本生成）等。
- 典型示例：机器翻译（如“你好吗”翻译为“How are you”），需捕捉序列中词语的依赖关系。

### 网络结构组成

RNN由输入、隐状态及输出三部分组成：
- 当前输入：$x_{t}$
- 上一时刻状态（历史信息）：$h_{t-1}$
- 更新后的当前状态：$h_{t}$
- 输出：$y_{t}$
- 权重矩阵：$W^{(hh)}$（隐层到隐层）、$W^{(hx)}$（输入到隐层）、$W^{(s)}$（隐层到输出层）

### 核心计算公式

- 隐状态更新：$h_{t}=\sigma (W^{(hh)}h_{t-1}+W^{(hx)}x_{t})$，其中$\sigma$为激活函数；
- 输出计算：$y_{t}=\text{softmax}\left(W^{(s)} h_{t}\right)$。

### 训练方法：时序反向传播（Back Prop Through Time, BPTT）

- 链式法则应用：计算权重梯度时，需追溯历史时刻的隐状态影响，即：
  $$\frac{\partial h_{t}}{\partial h_{k}}=\prod_{j=k+1}^{t} \frac{\partial h_{j}}{\partial h_{j-1}}=\prod_{j=k+1}^{t} W^{hh^{T}} diag\left[f'\left(h_{j-1}\right)\right]$$
- 权重梯度计算（以$W^{(hh)}$为例）：
  $$\frac{\partial E_{t}}{\partial W^{(h h)}}=\sum_{k=1}^{t} \frac{\partial E_{t}}{\partial y_{t}} \frac{\partial y_{t}}{\partial h_{t}} \frac{\partial h_{t}}{\partial h_{k}} \frac{\partial h_{k}}{\partial W^{(h h)}}$$
  $$\frac{\partial E}{\partial W^{(h h)}}=\sum_{t=1}^{T} \frac{\partial E_{t}}{\partial W^{(h h)}}$$

### 核心问题：梯度消失/梯度爆炸

- 问题根源：处理长序列时，$t$与$k$相差较大，梯度乘积项$\left(\beta_{W^{h h}} \beta_{h}\right)^{t-k}$（其中$\beta_{W^{hh}}$为$\left\|W^{hh^{T}}\right\|$上限，$\beta_{h}$为$\left\|diag\left[f'(h_{j-1})\right]\right\|$上限）可能趋近于0（梯度消失）或无穷大（梯度爆炸）；
- 解决方法：引入长短期记忆网络（LSTM）等改进结构。

## 长短期记忆网络（Long Short Term Memory, LSTM）

### 核心目标

解决RNN在长序列处理中遇到的长期依赖问题，通过门控单元控制信息的存储、遗忘与输出。

### 网络结构：LSTM单元（Cell）

LSTM单元由遗忘门、输入门、细胞状态、输出门组成，核心是通过门控机制调节细胞状态（$C_t$）的信息流转。

### 核心计算公式

#### 1. 遗忘门（Forget Gate）

- 作用：选择哪些历史信息应被遗忘；
- 计算：$f_{t}=\sigma (W_{f}\cdot [h_{t-1},x_{t}]+b_{f})$，输出介于0-1之间（0表示完全遗忘，1表示完全保留）。

#### 2. 输入门（Input Gate）

- 作用：选择哪些新信息应被存入细胞状态；
- 计算：$i_{t}=\sigma (W_{i}\cdot [h_{t-1},x_{t}]+b_{i})$；
- 候选细胞状态：$\tilde{C}_{t}=\tanh(W_{\tilde{C}} \cdot [h_{t-1}, x_t] + b_{\tilde{C}})$。

#### 3. 细胞状态更新

- 公式：$C_{t} = f_{t} \otimes C_{t-1} + i_{t} \otimes \tilde{C}_{t}$，其中$\otimes$为元素-wise乘法；
- 逻辑：先通过遗忘门丢弃无关历史信息，再通过输入门将新信息融入细胞状态。

#### 4. 输出门（Output Gate）

- 作用：选择细胞状态中哪些信息应输出为当前隐状态；
- 计算：$o_{t}=\sigma (W_{o}\cdot [h_{t-1},x_{t}]+b_{o})$；
- 隐状态输出：$h_{t}=o_{t} \otimes \tanh \left(C_{t}\right)$。

### 性能优势

在需要捕捉长期依赖关系的任务中表现更优，例如股票预测任务中，LSTM平均正确率（0.65）高于传统RNN（0.61）。

## 递归神经网络的应用

- 时间序列预测：股票价格预测、气象数据预测；
- 自然语言处理：机器翻译、文本生成、情感分析；
- 其他场景：语音识别、视频行为分析等。

# 7.5 自编码器

## 自编码器的定义

自编码器（Autoencoder）是一种用于半监督学习和非监督学习的神经网络，主要通过学习重构输入信息来进行表征学习。

## 自编码器的结构

- 包含两个神经网络，分别为编码器（Encoder）和解码器（Decoder）。
- 编码器：将读入的原始数据（图像、文字等）转换为向量。
- 解码器：将上述的向量还原成原始数据的形式。

## 深度自编码器（Deep Autoencoder）

- 深度自编码器是自编码器结构的简单改进，用深度神经网络代替编码器和解码器。
- 引入了深度神经网络强大的拟合能力，使得编码的维度能够比原始图像的维度低非常多。

## 自编码器的训练流程

- 训练目标：编码器输出的结果能够与原始数据尽可能的接近。
- 训练过程：输入数据经编码器压缩成低维表示，再由解码器还原，通过优化重构损失来调整网络权重，以此减少输入输出差异。
- 常用重构损失：均方误差损失等。
- 核心作用：可用于特征提取，将原始数据（高维、复杂）经过编码器后得到的向量（经过处理，低维）作为下游任务的输入。

## 自编码器的应用：工业异常检测

### 应用背景

- 工业异常检测的主要目的是在生产过程中监测并识别异常状态或设备故障，防止设备损坏和生产停滞。
- 在复杂多变的工业环境中，传统监控如阈值设置或规则系统往往难以处理高维数据和非线性系统带来的异常。
- 自编码器通过学习正常数据的压缩表示来识别异常数据，适用于难以定义明确正常行为规范的情况，能够有效识别细微的异常模式。

### 检测流程

1. 用正常的数据训练自编码器，自编码器学习对正常数据的重建。
2. 测试时输入正常数据，自编码器能够将其重建，输出和输入之间相似度较大。
3. 测试时输入异常数据，自编码器难以将其重建，输出和输入之间相似度较小。
4. 对于相似程度低于一定阈值的数据，将其识别为异常数据。

## 深度自编码器的不足

- 没有达到生成模型的标准：对于规定维度下任意采样的编码，解码器难以产生一张清晰且真实的图片。
- 编码空间特性：深度自编码器使用非线性深度神经网络变换进行编解码，导致在编码空间中的点呈离散分布，主要学习解码这些离散点，处理任意采样编码时存在困难。

## 自编码器的延伸应用：图像生成

- 原理：训练完自编码器后，解码器可单独作为生成器使用，将随机从分布中采样生成的向量转换为图像输出。

## 变分自编码器（Variational Autoencoder, VAE）

### 核心改进

变分自编码器的解码器可以从任意采样的编码生成图像，关键是为编码添加合适的高斯噪音。

### 结构特点

- 编码器会输出两个编码：一个是原有编码$S$，另外一个是噪音干扰权重的编码$\sigma$。
- 编码生成：$H = \log(S) \times N + O$，其中$N$从正态分布采样。
- 核心作用：引入高斯噪声，扩大图像的编码区域，使图像的编码由离散的编码点变成一条连续的编码分布曲线。

### 损失函数

1. 重构损失：$(x-\tilde{x})^{2}$
2. 正则化损失：$\log L - R + L + O^2$

# 7.6 生成式对抗神经网络

## 生成式对抗神经网络概述

### 核心思路

生成式对抗神经网络（Generative Adversarial Networks, GAN）是一种生成模型，通过生成器与判别器的博弈训练，使生成器能够生成逼真的数据样本，无需对潜在空间做明确分布假设。

### 与变分自编码器（VAE）的区别

VAE通过在潜在空间施加概率分布约束实现数据表示和生成；GAN无明确分布假设，依赖生成器与判别器的对抗过程学习数据分布。

### 生成模型的核心步骤

1. 密度估计：学习训练数据的数据分布；
2. 采样：从学习到的分布中采样生成新样本。

## 模型结构

### 生成器（Generator, G）

- 输入：潜在空间（Latent Space）中随机采样的向量（随机噪声）$z \sim p(z)$（如$z \sim N(0,1)$）；
- 目标：输出结果$x' = G_{\theta}(z)$尽量模仿训练集中的真实样本$x$；
- 核心作用：学习真实数据分布，生成逼真的伪造样本。

### 判别器（Discriminator, D）

- 输入：真实图片$x \sim p_{data}(x)$或生成器的输出$x' \sim p_G(x)$；
- 目标：将生成器生成的伪造样本与真实样本尽可能区分开，输出判别分数（0~1之间，1表示真实样本，0表示伪造样本）；
- 核心作用：作为“裁判”，推动生成器提升生成样本的逼真度。

## 训练与推理

### 优化目标函数

GAN的核心优化目标为极小极大博弈：
$$min _{G} max _{D} V(G, D) = E_{x\sim P_{data}}[log D(x)] + E_{z\sim P_{z}(z)}[log (1-D(G(z)))]$$

其中$G^{*}=\arg\min_{G} \max_{D} V(G, D)$，即生成器最小化判别器的区分能力，判别器最大化对真实样本和伪造样本的区分能力。

### 对抗训练过程

#### 1. 判别器训练（固定生成器G）

- 目标：最大化判别准确率，优化函数为：
$$max _{ø} E_{x \sim p_{data }(x)}[log D(x; ø)] + E_{z \sim p(z)}[log (1-D(G(z; \theta); ø))]$$
- 最优判别器：当生成器固定时，最优判别器为：
$$D_{G}^{*}(x)=\frac {p_{data }(x)}{p_{data }(x)+p_{G}(x)}$$

#### 2. 生成器训练（固定判别器D）

- 目标：最小化判别器的区分能力，即最大化判别器将伪造样本误判为真实样本的概率，优化函数为：
$$max _{\theta} E_{z \sim p_{(z)}}[log D(G(z ; \theta) ; ø))]$$
- 等价优化目标：固定D时，生成器的优化目标可转化为：
$$C(G)=max _{D}V(G,D)=E_{x\sim p_{data}}[log D_{G}^{*}(x)] + E_{x\sim p_{g}}[log (1-D_{G}^{*}(x))]$$
$$=E_{x\sim p_{data}}\left[ log \frac {p_{data}(x)}{p_{data}(x)+p_{g}(x)}\right] + E_{x\sim p_{g}}\left[ log \frac {p_{g}(x)}{p_{data}(x)+p_{g}(x)}\right]$$
- 收敛条件：生成器收敛到真实分布$p_G = p_{data}$，此时判别器无法区分真实样本和伪造样本，$D(x) = 0.5$。

### 推理过程

训练完成后，仅使用生成器进行推理：从潜在空间随机采样向量$z$，输入生成器$G$，直接输出生成的样本（如图像、文本等）。

## 存在的问题

### 模式坍塌（Mode Collapse）

- 定义：生成器在训练过程中过于集中于生成某一类或少数几类样本，忽略其他可能的样本类型，导致生成的样本缺乏多样性。
- 主要原因：生成器和判别器之间的对抗训练过程不稳定，生成器为了“欺骗”判别器，只专注于优化少数易被误判的样本模式。

## 相关变体和改进

### 训练优化类变体

#### LSGAN（Least Squares GAN，2016年Mao等人提出）

- 核心改进：使用最小二乘误差代替二元交叉熵作为损失函数。
- 优势：
  1. 稳定梯度：最小二乘损失提供平滑梯度，避免梯度消失；
  2. 鼓励多样性：生成器倾向于生成与真实样本接近的多样化样本。

#### WGAN（Wasserstein GAN，2017年Arjovsky等人提出）

- 核心改进：采用Wasserstein距离衡量生成样本与真实样本之间的差距。
- 优化措施：采用权重剪裁和梯度惩罚提高训练稳定性。

### 结构优化类变体

#### CGAN（Conditional GAN，2014年Mirza等人提出）

- 核心改进：在生成器和判别器中加入条件信息（如类别标签、文本描述等）。
- 优势：增强生成样本的可控性，可定向生成特定类型的样本。

#### DCGAN（Deep Convolutional GAN，2015年Radford等人提出）

- 核心改进：使用CNN架构实现生成器和判别器。
- 优势：显著提升图像生成效果，成为后续GAN变体的基础架构。

#### CycleGAN（2017年Zhu等人提出）

- 核心改进：使用两个生成器实现图像在源领域和目标领域间的双向转化。
- 优势：实现无监督的图像到图像转换（如风格迁移、图像修复等）。

# 7.7 Transformer网络

## Transformer网络概述

### 传统模型的局限性

- 长距离依赖问题：RNN随着序列长度增加，难以捕捉序列首尾间的依赖关系；
- 并行计算问题：RNN需按序列顺序逐个处理元素，限制训练并行化；
- 上下文建模局限：CNN和RNN的上下文捕捉窗口或范围固定，灵活性不足。

### Transformer的核心创新

- 提出时间：2017年由Google团队提出；
- 核心特点：完全摒弃循环神经网络结构，仅依赖注意力机制建模序列数据；
- 优势：更高效、灵活地处理序列数据，支持大规模并行训练。

## 注意力机制

### 核心定义

注意力机制是模拟人类选择性关注关键信息的信息处理方式，在处理数据时集中关注核心内容，忽略无关因素。

### 核心组件

- 查询（Query, Q）：自主提示的特征向量，代表查询范围；
- 键（Key, K）：被比对的项，代表物体的突出特征向量；
- 值（Value, V）：代表物体本身的特征向量，通常与Key成对出现。

### 实现步骤

1. 计算注意力评分：查询（Query）与键（Key）计算相似度，通过SoftMax函数得到显著性权重；
2. 加权求和：根据注意力权重对值（Value）进行加权求和，得到注意力输出。

### 缩放点积注意力

是Transformer中注意力机制的核心实现方式，通过对Q和K的点积结果进行缩放，避免因维度过高导致的数值溢出问题。

### 自注意力机制（Self-Attention）

- 核心区别：注意力机制的Q和K来自不同来源，自注意力机制的Q、K、V来自同一组元素；
- 优势：减少对外部信息的依赖，擅长捕捉数据或特征的内部相关性；
- 示例：处理文本“Beijing Winter Games”时，可捕捉“Beijing”与“Games”的关联，形成“冬奥会”的语义理解。

### 多头注意力机制（Multi-Head Attention）

- 核心思想：将Q、K、V通过不同的投影矩阵映射到多个子空间，每个子空间独立计算注意力，最后将结果拼接融合；
- 数学表达：$h_{i}=f(W_{i}^{q} q, W_{i}^{k} k, W_{i}^{v} v) \in \mathbb{R}^{p_{v}}$，其中$h_i$为第$i$个注意力头的输出，$W_{i}^{q}$、$W_{i}^{k}$、$W_{i}^{v}$分别为第$i$个注意力头的Q、K、V投影矩阵；
- 优势：不同注意力头可关注不同类型的特征，提升模型对复杂信息的捕捉能力。

## 模型结构

### 整体架构

以机器翻译（输入“Beijing Winter Games”，输出“北京冬奥会”）为例，Transformer由编码器（Encoder）和解码器（Decoder）两部分组成，采用编码器-解码器架构。

### 编码器（Encoder）

#### 核心结构（每层包含）

1. 自注意力模块：捕捉输入序列内部的依赖关系；
2. 前馈网络（FFN）：对注意力输出进行非线性变换，总结高级语义特征；
3. 归一化层（Normalization）：稳定反向传播梯度，加速训练收敛；
4. 残差链接（Residual Connection）：将模块输入直接叠加到输出，避免梯度消失。

#### 结构特点

多层编码器堆叠而成，所有编码器结构相同但参数独立，通过自注意力机制和前馈网络的组合，逐步提取输入序列的高级语义特征。

### 解码器（Decoder）

#### 核心结构（每层包含）

1. 自注意力模块：捕捉输出序列内部的依赖关系（如翻译结果中词语的顺序关联）；
2. 编解码注意力机制（Encoder-Decoder Attention）：Q来自Decoder上一层输出，K和V来自Encoder的最终输出，使Decoder关注输入序列的相关信息；
3. 前馈网络（FFN）：对特征进行非线性变换；
4. 归一化层和残差链接：功能与编码器一致。

#### 结构特点

多层解码器堆叠而成，通过自注意力机制保证输出序列的连贯性，通过编解码注意力机制关联输入与输出的语义信息。

### 输入处理

#### 输入编码

- 目标：将输入Token序列转换为特征序列；
- 示例：文本输入“Beijing Winter Games”→分词为[‘Beijing’, ‘Winter’, ‘Games’]→映射为Token值[1,2,3]→通过嵌入层（Embedding）转化为特征向量。

#### 位置编码

- 必要性：Transformer无循环或卷积结构，需通过位置编码引入序列的相对或绝对位置信息；
- 常用方法：
  - 绝对位置编码：对序列中每个位置进行差异化编码；
  - 相对位置编码：根据词之间的相对距离进行编码；
  - 旋转位置编码：统一绝对位置编码和相对位置编码的优势。

### 输出处理

- 线性层：将解码器输出映射到词表大小的维度；
- SoftMax层：将线性层输出转化为概率分布，选择概率最高的Token作为输出结果。

## 训练与推理

### 模型训练

#### 并行训练

- 训练数据处理：将训练数据向左平移1位作为输出真值（如输入“<SOS> 北 京 冬 奥 会”，输出“北 京 冬 奥 会 <EOS>”）；
- Teacher-forcing策略：Decoder的输入采用真实标签（而非模型预测值），加速训练收敛；
- 损失函数：交叉熵损失，衡量模型预测值与真实标签的差距。

#### 训练目标

最小化预测序列与真实序列的交叉熵损失，使模型学习到输入与输出之间的映射关系。

### 模型推理

#### 串行自回归推理

1. 初始步骤：输入<SOS>（Start of Sentence）作为句子开始标志；
2. 迭代生成：将上一步生成的Token作为Decoder的输入，预测下一个Token；
3. 终止条件：当模型输出<EOS>（End of Sentence）时，停止生成，得到完整输出序列。

## 相关变体和应用

### NLP领域应用

- GPT系列：2018年OpenAI提出GPT，2019年推出GPT-2.0，2020年发布GPT-3.0，2022年基于GPT-3推出ChatGPT，成为主流对话语言模型；
- BERT：2019年Google提出，采用双向自注意力机制，在文本分类、问答等任务中表现优异；
- T5：2019年Google提出，基于Encoder-Decoder架构，统一各类NLP任务为文本生成任务。

### CV领域应用

- ViT（Vision Transformer）：将Transformer应用于计算机视觉，通过图像分块和位置编码，将图像转化为序列数据，成为视觉任务的骨干网络；
- DETR：基于Transformer的目标检测模型，通过编码器-解码器架构和二分图匹配损失，直接输出目标检测框和类别；
- TransTrack：基于Transformer的目标跟踪模型，利用注意力机制捕捉目标与背景的关联信息。