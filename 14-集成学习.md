# 14.1 什么是集成学习？

## 集成学习的基本概念

- 集成学习(Ensemble Learning)：通过构建并结合多个分类器完成学习任务，也称为多分类器系统 (Multi-Classifier System)、基于委员会的学习 (Committee based Learning) 等。
- 学习器分类：
  - 同质：基学习器(Base learner)；
  - 异质：组件学习器(Component learner)。
- 核心作用：通过将多个学习器进行集成，常可获得比单一学习器显著优越的泛化性能，这对弱学习器尤为明显。
  - 弱学习器：准确率仅比随机猜测略高的学习器；
  - 强学习器：准确率高并能在多项式时间内完成的学习器；
  - 集成效果：弱学习器集成可成为强学习器，强学习器集成可成为更强的学习器。

## 个体与集成

### 核心疑问

多个学习器不一定比单一学习器性能好，存在集成不起作用、起负作用或提升性能三种情况，关键在于个体学习器需“好而不同”。

### 简单分析
- 二分类问题设定：设二分类问题 $y \in \{-1,+1\}$ 和真实函数 $f$，基分类器的错误率为 $\epsilon$，即对每个基分类器 $h_{i}$ 有 $P(h_{i}(x) \neq f(x))=\epsilon$。
- 集成投票规则：集成通过简单投票法结合 $T$ 个基分类器 $\{h_{i}\}_{i=1}^{T}$，若有超过半数的基分类器正确则分类正确，集成输出为：
$$H(x)=sign\left(\sum_{i=1}^{T} h_{i}(x)\right)$$
- 关键假设：基学习器的误差相互独立，但现实任务中，个体学习器是为解决同一个问题训练出来的，不可能互相独立。
- 核心冲突：个体学习器的“准确性”和“多样性”存在冲突。
- 研究核心：如何产生并结合“好而不同”的个体学习器。
- 误差特性：假设基分类器的错误率相互独立，则由Hoeffding不等式可知，集成的错误率为至多半数基分类器分类正确的概率，随着集成分类器数目的增加，集成的错误率将指数级下降，最终趋向于0，公式表示为：
$$P(H(x) \neq f(x)) = \sum_{k=0}^{\lfloor T/2 \rfloor} \binom{T}{k} \epsilon^k (1-\epsilon)^{T-k} \leq \exp \left(-\frac{1}{2} T(1-2 \epsilon)^{2}\right)$$

# 14.2 串行化集成学习算法

## Boosting算法

### 基本思想

- 串行式集成学习代表性方法：一族可将弱学习器提升为强学习器的算法。
- 核心思想：迭代训练多个弱学习器，每次着重改进前一次的错误，从而将多个弱学习器组合成一个强学习器。
- 核心步骤：
  1. 先从初始数据集训练一个基学习器；
  2. 再根据其对训练样本分布进行调整，使先前错分样本在后续受到更多关注；
  3. 然后基于调整后的样本分布训练下一个基学习器；
  4. 重复进行直至基学习器数目达到预先指定值，最终将这些基学习器加权结合，集成输出为：
$$H(x)=sign\left(\sum_{t=1}^{T} \alpha_{t} h_{t}(x)\right)$$

### 基学习器学习特定的数据分布

- 重赋权(Re-weighting)：在每轮根据样本分布为每个训练样本重新赋予权重。
- 重采样(Re-sampling)：在每轮根据样本分布对训练集重新采样形成新的训练集。
- 注意事项：Boosting每轮检查当前生成的基学习器是否满足优于随机猜测的基本条件，若不满足，此基学习器被抛弃，学习过程停止；如果与预先设定的学习轮数差距较大，会导致整体性能不佳；采用重采样策略，则可“重启动”避免训练过早停止。

### 特点总结

- Boosting中每个模型是弱模型，偏差高，方差低；
- 个体学习器存在强依赖关系，串行生成，每次调整训练数据的样本分布；
- Boosting的基本思想是用贪心法最小化损失函数，主要关注降低偏差；
- 由于模型的相关性很强，因此不能显著降低方差。

## AdaBoost算法

### 基本定位

- Boosting族算法最著名的代表【1997年Freund和Schapire提出】。
- 核心框架：基于“加性模型”(Additive Model)，即基学习器线性组合：$H(x)=\sum_{t=1}^{T} \alpha_{t} h_{t}(x)$，最小化指数损失函数：
$$\ell _{exp }(H|\mathcal {D})=\mathbb {E}_{x\sim \mathcal {D}}\left[ e^{-f(x)H(x)}\right]$$

### 关键特性

- 若$H(x)$能令指数损失函数最小化，可得$H(x)=\frac{1}{2} ln \frac{P(f(x)=1 | x)}{P(f(x)=-1 | x)}$，进而：
$$\begin{aligned} sign(H(x)) & =sign\left(\frac{1}{2} ln \frac{P(f(x)=1 | x)}{P(f(x)=-1 | x)}\right) \\ & = \begin{cases}1, & P(f(x)=1 | x)>P(f(x)=-1 | x) \\ -1, & P(f(x)=1 | x)<P(f(x)=-1 | x)\end{cases} \\ & =\underset{y \in\{-1,1\}}{arg max } P(f(x)=y | x) \end{aligned}$$
- $sign(H(x))$达到了贝叶斯最优错误率，说明指数损失函数是分类任务原来0/1损失函数的一致替代损失函数。

### 算法流程

- 输入：训练集$D=\left\{(x_{1}, y_{1}),(x_{2}, y_{2}), \cdots,(x_{m}, y_{m})\right\}$，基学习算法$Q$，训练轮数$T$（$f$为真实函数，$y \in \{-1,+1\}$）；
- 过程：
  1. 初始化样本权值分布：$\mathcal{D}_{1}(x)=\frac{1}{m}$；
  2. 对$t=1,2,...,T$执行：
     - 基于分布$\mathcal{D}_{t}$训练分类器$h_{t}=Q(D, \mathcal{D}_{t})$；
     - 估计$h_{t}$的误差：$\epsilon_{t}=P_{x \sim \mathcal{D}_{t}}\left(h_{t}(x) \neq f(x)\right)$；
     - 若$\epsilon_{t}> 0.5$则break；
     - 确定分类器$h_{t}$的权重$\alpha_{t}$；
     - 更新样本分布（$Z_{t}$为规范化因子）：
$$\mathcal{D}_{t+1}(x)=\frac{\mathcal{D}_{t}(x)}{Z_{t}} \times \begin{cases}\exp \left(-\alpha_{t}\right), & if h_{t}(x)=f(x) \\ \exp \left(\alpha_{t}\right), & if h_{t}(x) \neq f(x)\end{cases}$$
  3. 集成分类器输出：$H(x)=sign\left(\sum_{t=1}^{T} \alpha_{t} h_{t}(x)\right)$；
- 输出：集成分类器$H(x)$。

# 14.3 并行化集成学习算法

## Bagging算法

### 基本定位
- 并行式集成学习最著名的代表性方法，名字由Bootstrap AGGregatING缩写而来【1993年Efron和Tibshirani提出】。
- 核心机制：基于自助采样法 (Bootstrap Sampling)，通过为不同学习器构建不同训练数据集，增加学习器的多样性。

### 自助采样法流程
- 给定包含$m$个样本的数据集$D$，对其进行采样产生数据集$D'$：
  1. 每次随机从$D$中挑选一个样本，将其拷贝至$D'$；
  2. 重复执行$m$次后，得到包含$m$个样本的数据集$D'$；
  3. 样本在$m$次采样中始终不被采到的概率是$(1-\frac{1}{m})^m$，其极限为：
$$\lim _{m \to \infty}(1-\frac{1}{m})^{m} \to \frac{1}{e} \approx 0.368$$
  4. 应用方式：将$D'$用做训练集，$D \setminus D'$用作测试集。

### 基本思想

- 利用自助法采样可构造$T$个含$m$个训练样本的采样集，基于每个采样集训练出一个基学习器，再将它们进行结合。
- 预测输出结合策略：
  - 分类任务使用简单投票法；
  - 回归任务使用简单平均法。

### 算法应用

- Bagging算法可应用于任何机器学习模型，具体场景取决于基学习器的选择：
  - 分类任务：如判断航空发动机是否过热，基学习器可选用决策树、支持向量机等；
  - 回归任务：如预测飞机与目标距离，基学习器可选用回归模型等。

### 特点总结
- 方差低：集成多个独立训练的基学习器可以有效降低方差，在易受样本扰动的学习器上效用更为明显（如不剪枝的决策树、神经网络等）；
- 易于并行：由于各个基学习器互相独立，训练与推理都可并行化处理；
- 无法降低偏差：利用样本扰动构建的基学习器的偏差与原学习器近似相同，但互相间相关性不高，因此一般不能降低偏差，只能在一定程度上降低方差；
- 资源需求大：训练与推理阶段都需运行多个基学习器，对计算资源要求较高。

## 随机森林算法

### 基本定位

- Bagging方法的一种扩展变体【2001年Breiman提出】，以决策树为基学习器。
- 与Bagging的核心区别：Bagging仅进行数据随机选择，随机森林在训练过程中额外引入随机属性选择。

### 基本思想
- 结构组成：由若干决策树组成，通过Bagging算法和随机属性选择策略实现“好而不同”的个体学习器集成。
- 属性选择机制：
  1. 对每个决策树结点，先从该结点的$d$个属性集合中随机选择包含$k$个属性的子集；
  2. 从选中的属性子集中选择一个最优属性用于划分；
  3. 属性子集大小推荐：一般情况下推荐$k=\log _{2} d$。

### 算法特点

- 基学习器多样性来源：通过样本扰动（自助采样）和属性扰动（随机属性选择）双重机制实现；
- 算法优势：算法简单、容易实现、计算开销小；
- 性能表现：与Bagging方法相比性能更强，被誉为“代表集成学习技术水平的方法”。

### Bagging vs. 随机森林
- 收敛性相似：错误率随着基分类器数量增加最终趋于稳定；
- 训练效率差异：随机森林使用少量基分类器即可取得比Bagging方法更低的错误率，训练效率更优。

# 14.4 集成学习的结合策略及多样性

## 结合策略

- 学习器的组合有三个方面的好处【Dietterich, 2000】：
  1. 统计方面：减小误选假设空间导致泛化性能不佳的几率；
  2. 计算方面：降低陷入坏局部极小点影响泛化性能的风险；
  3. 表示方面：扩大假设空间学习对于真实空间更好的近似。

### 平均法 (Averaging)

- 是数值型输出最常见的结合策略。
- 简单平均法 (Simple Averaging)：个体学习器性能相近时适用，公式为：
$$H(x)=\frac{1}{T} \sum_{i=1}^{T} h_{i}(x)$$
- 加权平均法 (Weighted Averaging)：个体学习器性能迥异时适用，公式为：
$$H(x)=\sum _{i=1}^{T} w_{i} h_{i}(x), \quad w_{i} \geq 0 \text{ 且 } \sum_{i=1}^{T} w_{i}=1$$
- 说明：【1993年Perrone和Cooper正式将其用于集成学习】，加权平均法是集成学习的基本出发点，各种结合方法都可视为其特例或变体，不同的集成学习方法是通过不同的方式确定加权平均法中基学习器的权重。

### 投票法 (Voting)

- 是标签型输出最常见的结合策略。
- 基础定义：标记集合 $\{c_{1}, c_{2}, \cdots, c_{N}\}$，$h_{i}$ 在样本 $x$ 上的预测为 $\{h_{i}^{1}(x), h_{i}^{2}(x), \cdots, h_{i}^{N}(x)\}$，分为硬投票（类标签）和软投票（类概率）。
- 具体类型：
  1. 绝对多数投票法 (Majority Voting)：得票超半数；
  2. 相对多数投票法 (Plurality Voting)：得票最多；
  3. 加权投票法 (Weighted Voting)：加权后得票最多，公式为：
$$H(x)=c_{\arg \max _{j}} \sum_{i=1}^{T} w_{i} h_{i}^{j}(x)$$

### 学习法

- 核心思想：当训练数据很多时采用另一个学习器进行结合。
- 学习器分类：初级学习器 vs. 次级学习器（或元学习器 (Meta-learner)）。
- 典型代表：Stacking【1992年Wolpert提出】。
- 流程：
  1. 从初始数据训练初级学习器；
  2. 生成次级数据集：初级学习器的输出被当作样例输入特征，继承初始样本标记；
  3. 从次级数据训练次级学习器。

## 多样性

### 简单分析

- 关键假设：基学习器的误差相互独立，但现实任务中，个体学习器是为解决同一个问题训练出来的，显然不可能互相独立；
- 核心冲突：个体学习器的“准确性”和“多样性”存在冲突；
- 研究核心：如何产生并结合“好而不同”的个体学习器。

### 误差-分歧分解

- 适用场景：假设个体学习器 $\{h_{1}, h_{2}, \cdots, h_{T}\}$ 通过加权平均法结合产生集成，用于回归学习任务 $f: \mathbb{R}^{d} \mapsto \mathbb{R}$。
- 核心定义：
  1. 分歧 (Ambiguity)：表征个体学习器在样本 $x$ 上的不一致性，在一定程度上反映个体学习器的多样性；
  2. 个体学习器 $h_{i}$ 和集成 $H$ 的平方误差：$\bar{E}(h | x)=\sum_{i=1}^{T} w_{i} \cdot E(h_{i} | x)$（个体学习器误差的加权均值）。
- 关键公式：
  - 个体学习器泛化误差的加权均值：$\bar{E}=\sum_{i=1}^{T} w_{i} E_{i}$；
  - 个体学习器的加权分歧值：$\bar{A}=\sum_{i=1}^{T} w_{i} A_{i}$；
  - 全样本上的误差-分歧分解：
$$\sum_{i=1}^{T} w_{i} \int A\left(h_{i} | x\right) p(x) d x=\sum_{i=1}^{T} w_{i} \int E\left(h_{i} | x\right) p(x) d x-\int E(H | x) p(x) d x$$
  其中，集成的泛化误差为 $E=\int E(H | x) p(x) d x$。
- 结论【1995年Krogh和Vedelsby给出】：“个体学习器精确性越高、多样性越大，则集成效果越好”。

### 多样性度量 (Diversity Measure)

- 核心用途：用于度量集成中个体学习器的多样性，考虑个体学习器的两两相似/不相似性。
- 二分类任务联立表 (Contingency Table)：给定数据集 $D=\{(x_{1}, y_{1}),(x_{2}, y_{2}), \cdots,(x_{m}, y_{m})\}$，分类器 $h_{i}$ 与 $h_{j}$ 的预测结果联立表为：

| | $h_{i}=+1$ | $h_{i}=-1$ |
| --- | --- | --- |
| $h_{j}=+1$ | $a$ | $b$ |
| $h_{j}=-1$ | $c$ | $d$ |

- 具体度量方式：
  1. 不合度量 (Disagreement Measure)：$Q_{i j}=\frac{a d-b c}{a d+b c}$，值域[0, 1]，值越大多样性越大；
  2. 相关系数 (Correlation Coefficient)：值域[-1, 1]，学习器无关值为0；正相关值为正，否则为负；
  3. Q-统计量 (Q-Statistic)：$Q_{i j}$ 与相关系数 $\rho_{i j}$ 符号相同，且 $|Q_{i j}| \leq|\rho_{i j}|$；
  4. Kappa-统计量 (Kappa-Statistic)：$\kappa=\frac{p_{1}-p_{2}}{1-p_{2}}$，其中一致概率 $p_{1}=(a+d) / m$，偶然一致概率 $p_{2}=((a+b)(a+c)+(c+d)(b+d)) / m^{2}$；值域特性：学习器完全一致值为1；偶然一致值为0，一致概率低于偶然取负值。

### 多样性增强

- 核心思想：在学习过程引入随机性，不同的多样性增强机制可一起使用。
- 具体方式：
  1. 数据样本扰动：通常基于采样法，对数据样本扰动敏感的基学习器（不稳定基学习器）如决策树、神经网络等效果明显；对不敏感的基学习器（稳定基学习器）如线性学习器、支持向量机等效果不明显；
  2. 输入属性扰动：不同子空间提供观察数据的不同视角，对包含大量冗余属性的数据效果好，属性数少或冗余少则不宜使用；
  3. 输出表示扰动：操纵输出表示，包括翻转法（随机改变一些训练样本的标记）、输出调制法（将分类输出转为回归输出构建个体学习器）、ECOC法（将多分类任务拆解为一系列二分类任务训练基学习器）；
  4. 算法参数扰动：随机设置不同的参数或环节，参数较多时可通过正则化项强制个体学习器使用不同参数，参数较少时可替换算法内部机制。
- 机制结合示例：
  - AdaBoost：加入了数据样本扰动；
  - 随机森林：同时加入了数据样本扰动和输入属性扰动。