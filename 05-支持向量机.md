# 5.1 线性支持向量机

## 建模方法

### 核心目标与样本集

- 样本集：$\left\{x_{n}, t_{n}\right\}, n=1,2, ..., N, x_{n} \in \mathbb{R}^{d}, t_{n} \in\{-1,1\}$，其中$t_n$为类别标记。
- 核心目标：寻找最大化分类间隔的超平面$w^T x + b = 0$，使模型泛化性能最优。

### 优化问题转化

#### 原始目标（最大间隔）

$$max _{w, b}\left\{\frac{1}{\| w\| } min _{n}\left[t_{n}\left(w^{T} x_{n}+b\right)\right]\right\}$$

约束条件：$t_{n}\left(w^{T} x_{n}+b\right) \geq 1, n=1,...,N$（所有样本落在间隔边界外侧）。

#### 等价二次规划问题

将最大间隔目标等价转化为最小化权向量范数的二次规划问题：
$$min _{w, b} \frac{1}{2}\| w\| ^{2} \tag{5-2-1}$$

约束条件：$t_{n}\left(w^{T} x_{n}+b\right) \geq 1, n=1,...,N$。

## 模型推导

### 拉格朗日对偶性引入

为求解带约束的优化问题，引入拉格朗日乘子$a_n \geq 0$，构造拉格朗日函数：
$$L(w, b, a)=\frac{1}{2}\| w\| ^{2}-\sum_{n=1}^{N} a_{n}\left\{t_{n}\left(w^{T} x_{n}+b\right)-1\right\}, a_{n} \geq 0$$

### 原问题与对偶问题转化

- 原问题：$min _{w,b} \theta_{P}(w,b)=min _{w,b} max _{a ; a_{n} \geq 0} L(w, b, a)$，其中$\theta_{P}(w,b)=\left\{\begin{array}{c}\frac{1}{2}\|w\|^2, 若 w,b 满足约束条件 \\ +\infty, 否则 \end{array}\right.$。
- 对偶问题：直接求解原问题较困难，转向求解对偶问题$max _{a ; a_{n} \geq 0} \theta_{D}(a)=max _{a ; a_{n} \geq 0} min _{w,b} L(w, b, a)$。

### 对偶问题求解

对$w$和$b$求偏导并令其为0，得到极值条件：
$$\frac{\partial L(w, b, a)}{\partial w}=w-\sum_{n=1}^{N} a_{n} t_{n} x_{n}=0 \tag{5-2-3}$$
$$\frac{\partial L(w, b, a)}{\partial b}=\sum_{n=1}^{N} a_{n} t_{n}=0 \tag{5-2-3}$$

将上述条件代入拉格朗日函数，对偶问题转化为：
$$max _{a} \sum_{n=1}^{N} a_{n}-\frac{1}{2} \sum_{n=1}^{N} \sum_{m=1}^{N} a_{n} a_{m} t_{n} t_{m} x_{n}^{T} x_{m}$$

约束条件：$a_{n} \geq 0, n=1, ..., N$；$\sum_{n=1}^{N} a_{n} t_{n}=0$。

### KKT（Karush-Kuhn-Tucker）条件

原问题与对偶问题等价的充要条件的核心内容：
1. 偏导数为零：$\frac{\partial}{\partial w_{i}} L\left(w^{*}, b^{*}, a^{*}\right)=0$；
2. 互补松弛条件：$a_{n}^{*} \left\{t_{n}\left(w^{*T} x_{n}+b^{*}\right)-1\right\}=0$；
3. 原始约束满足：$t_{n}\left(w^{*T} x_{n}+b^{*}\right) \geq 1$；
4. 拉格朗日乘子非负：$a_{n}^{*} \geq 0$。

### 分类超平面与决策函数

#### 最优参数求解

- 最优权向量：$w^{*}=\sum_{n=1}^{N} a_{n}^{*} t_{n} x_{n}$（仅$a_{n}^{*}>0$的样本贡献，即支持向量）；
- 最优偏置项：$b^{*}=\frac{1}{N_{S}} \sum_{n \in S}\left(t_{n}-\sum_{m \in S} a_{m} t_{m} x_{n}^{T} x_{m}\right)$，其中$S$为支持向量集合，$N_S$为支持向量个数。

#### 最终模型

- 分类超平面：$w^{*T} x + b^{*}=0$；
- 决策函数：$y(x)=\sum_{n=1}^{N} a_{n}^{*} t_{n} x_{n}^{T} x + b^{*}$。

### 支持向量概念

满足$a_{n}^{*}>0$的样本为支持向量，对应$t_{n}\left(w^{*T} x_{n}+b^{*}\right)=1$，即落在间隔边界上；$a_{n}^{*}=0$的样本对应$t_{n}\left(w^{*T} x_{n}+b^{*}\right)>1$，落在间隔内部，不影响模型参数求解。

## 对比

| 方面       | 最小二乘准则                 | 支持向量机                  |
|----------|-------------------------|--------------------------|
| 优化目标    | 最小化误差平方和                | 最大化分类间隔                   |
| 关注点     | 所有样本的拟合误差               | 边界样本的间隔                    |
| 样本参与    | 所有样本都参与                  | 只有支持向量参与                    |
| 适用情况    | 线性可分和不可分                | 线性可分（硬间隔）                  |
| 对异常值    | 非常敏感                     | 相对不敏感                        |
| 解的唯一性   | 唯一（如果矩阵可逆）             | 唯一（最大间隔）                    |
| 稀疏性     | 不稀疏（所有样本参与）            | 稀疏（只有支持向量）                  |

# 软间隔

## 什么是软间隔

### 硬间隔的局限

硬间隔要求所有样本严格满足 $t_{n}\left(w^{T} x_{n}+b\right) \geq 1$，难以处理含噪声和离群点的样本：
- 样本中存在噪声或离群点时，求解的最优分类面可能过于贴近这些异常样本，导致泛化性能变差；
- 对于类别分布有交集的数据，无法找到无错分的硬间隔超平面，需允许一定范围内的“错分”，追求更大间隔的广义最优分类面。

### 软间隔的核心思想

通过引入**松弛变量** $\xi_n \geq 0$，允许部分样本不满足硬间隔约束，实现从硬间隔（Hard Margin）到软间隔（Soft Margin）的转变。

### 约束条件调整

将硬间隔的约束条件修改为：

$$t_{n}\left(w^{T} x_{n}+b\right) \geq 1-\xi_{n}$$

其中 $y(x_n) = w^T x_n + b$ 为分类函数。

其中 $\xi_n$ 的含义：
- $\xi_n=0$：样本满足硬间隔约束，落在最大间隔边界上或外侧；
- $0<\xi_n \leq1$：样本落在最大间隔内部，未被错分；
- $\xi_n>1$：样本被错分。

## 软间隔的求解

### 优化目标

$$min _{w, b, \xi_n} \frac{1}{2}\| w\| ^{2}+C \sum_{n=1}^{N} \xi_{n}$$

约束条件：
- $t_{n}\left(w^{T} x_{n}+b\right) \geq 1-\xi_{n}, n=1,...,N$；
- $\xi_{n} \geq 0, n=1,...,N$。

其中 $C>0$ 为惩罚系数，反映对离群点的容忍度：
- $C$ 越大，对离群点惩罚越重，模型越接近硬间隔；
- $C$ 越小，对离群点容忍度越高，允许更多样本偏离间隔边界。

### 拉格朗日函数构造

引入拉格朗日乘子 $a_n \geq 0$ 和 $\mu_n \geq 0$，构造拉格朗日函数：
$$L(w, b, \xi, a, \mu)=\frac{1}{2}\| w\| ^{2}+C \sum_{n=1}^{N} \xi_{n}-\sum_{n=1}^{N} a_{n}\left\{t_{n}\left(w^{T} x_{n}+b\right)-1+\xi_{n}\right\}-\sum_{n=1}^{N} \mu_{n} \xi_{n}$$

约束条件：$a_{n} \geq 0$；$\mu_{n} \geq 0$。

### 极值条件求解

对 $w, b, \xi_n$ 分别求偏导并令其为 0，得到极值条件：
1. 对 $w$ 求偏导：$\frac{\partial L}{\partial w}=0 \Rightarrow w=\sum_{n=1}^{N} a_{n} t_{n} x_{n}$；
2. 对 $b$ 求偏导：$\frac{\partial L}{\partial b}=0 \Rightarrow \sum_{n=1}^{N} a_{n} t_{n}=0$；
3. 对 $\xi_n$ 求偏导：$\frac{\partial L}{\partial \xi_{n}}=0 \Rightarrow a_{n}+\mu_{n}=C \Rightarrow a_{n}=C-\mu_{n}$。

### 对偶问题转化

将极值条件代入拉格朗日函数，软间隔的对偶问题为：
$$max _{a} \sum_{n=1}^{N} a_{n}-\frac{1}{2} \sum_{n=1}^{N} \sum_{m=1}^{N} a_{n} a_{m} t_{n} t_{m} x_{n}^{T} x_{m}$$

约束条件：

- $0 \leq a_{n} \leq C, n=1,2, ..., N$；
- $\sum_{n=1}^{N} a_{n} t_{n}=0$。

### KKT（Karush-Kuhn-Tucker）条件

软间隔最优解需满足以下 KKT 条件（$n=1, ..., N$）：
$$\begin{cases}
a_{n} \geq 0, \mu_{n} \geq 0, \xi_{n} \geq 0 \\
t_{n}\left(w^{T} x_{n}+b\right)-1+\xi_{n} \geq 0 \\
a_{n}\left\{t_{n}\left(w^{T} x_{n}+b\right)-1+\xi_{n}\right\}=0 \\
\mu_{n} \xi_{n}=0
\end{cases}$$