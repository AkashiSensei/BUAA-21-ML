# 12.1 什么是采样？

生成符合某个分布的一组数据。

## 采样的定义

- 采样是一种用有限个样本点来近似总体分布，并刻画总体分布中不确定性的方法。
- 基本思想：对于满足分布 $p(z)$ 的随机变量 $Z$，从分布 $p(z)$ 中独立抽取一组样本 $z^{(l)}$（其中 $l=1,2, ..., L$），其随机变量期望值可以近似为一个有限的和：
$$\mathbb{E}[f(z)]=\int f(z) p(z) d z \approx \frac{1}{L} \sum_{l=1}^{L} f(z^{(l)})$$

## 采样的应用

- 布丰投针问题：1777年法国科学家布丰（Buffon）提出的利用采样思想计算圆周率$\pi$的方法-随机投针法。
  1. 在平面上画上间距为$a$的平行线；
  2. 取一根长度为$l(l<a)$的针，随机投掷于平面上，针与任一线相交的概率$p=\frac{2 l}{\pi a}$；
  3. $\pi$的值可计算为：$\pi=\frac{2 l}{a p} \approx\frac{2 l}{a}(\frac{N}{n})$，其中$N$为总的投针次数，$n$为与平行线相交次数；
  4. 布丰投针问题是采样方法中蒙特卡洛方法的早期实例，为后来的许多数值计算方法奠定了基础。

- 复杂函数定积分的计算：对于解析形式难以求得的积分$\int_{b}^{a} f(x) d x$，可通过采样方法中蒙特卡洛方法求其近似值。
  1. 蒙特卡洛方法基本思想是把要求解的问题转化为求解某一随机事件的概率，或者某个随机变量的期望；
  2. 积分近似公式：$\int_{b}^{a} f(x) d x=\int_{b}^{a} \frac{f(x)}{q(x)} q(x) d x \approx \frac{1}{N} \sum_{i=1}^{N} \frac{f\left(x_{i}\right)}{q\left(x_{i}\right)}$；
  3. 其中$q(x)$是某种容易采样的分布，$x_{i}$是服从$q(x)$分布的随机样本。

- 扩散模型中的噪声采样：扩散模型是一类用于文生图的新兴生成模型，通过逐步去噪过程生成图像。
  1. 基本思想：图像生成从一个完全随机的噪声图像开始，模型逐步从一个噪声分布中利用马尔可夫蒙特卡洛采样来决定去噪的程度和方向，最终产生高质量的图像。

- 机器人导航：帮助机器人确定自身位置、规划路径，并安全到达目的地的技术和方法。
  1. 广泛应用的粒子滤波器是一种基于重要性采样的算法；
  2. 基本思想：通过为每个粒子分配权重来反映其对观测数据的适应程度，并通过重采样步骤保留高权重粒子，从而有效地估计系统的状态分布。

# 12.2 基本采样法

## 思想

需要分布函数已知。

- 基本采样法 (Basic Sampling) 的核心思想：从均匀分布中通过函数变换产生目标分布。
  - 均匀分布 (Bootstrap Sampling)：
$$p(z)=1, \quad z\in (0,1)$$
  - 通过函数变换：$y=f(z)$
  - 产生目标分布：$p(y)$
- 关键问题：如何构造函数变换 $f$？

## 构造函数变换

- 设 $z$ 有概率密度函数 $p(z)$，而 $y=f(z)$ 构成 $z$ 到 $y$ 的一一对应变换，则 $y$ 的概率密度函数为：
$$p(y)=p(z)\left|\frac{d z}{d y}\right|$$
- 结合均匀分布，令 $z=h(y) \equiv \int_{-\infty}^{y} p(\hat{y}) d \hat{y}$（$h(y)$ 为累积分布函数 (CDF)），则有：
$$y=h^{-1}(z)$$

## 算法流程

基本采样法通过以下步骤实现：
1. 确定目标分布的概率密度函数 $p(y)$；
2. 计算目标分布的累积分布函数 $h(y)=\int_{-\infty}^{y} p(\hat{y}) d \hat{y}$；
3. 求解累积分布函数的逆函数 $h^{-1}(z)$；
4. 从均匀分布 $U(0,1)$ 中采样得到 $z^{(l)}$（$l=1,2,...,L$）；
5. 通过逆函数变换 $y^{(l)}=h^{-1}(z^{(l)})$，得到目标分布的样本集 $\{y^{(l)}\}$。

## 实例

### 实例1：指数分布

- 已知 $z \sim U(0, 1)$，目标分布 $p(y)=\lambda exp(-\lambda y)$；
- 计算目标分布的累积分布函数：
$$h(y)=\int_{-\infty}^{y} p(y) d y=1-exp(-\lambda y)$$
- 求解逆函数：
$$y=h^{-1}(z)=-\lambda^{-1} ln(1-z)$$

### 实例2：标准柯西分布

- 已知 $z \sim U(0, 1)$，目标分布 $p(y)=\frac{1}{\pi} \frac{1}{1+y^{2}}$；
- 计算目标分布的累积分布函数：
$$h(y)=\int_{-\infty}^{y} p(y) d y=\frac{1}{\pi} arctan(y)+\frac{1}{2}$$
- 求解逆函数：
$$y=h^{-1}(z)=\pi tan\left(z-\frac{1}{2}\right)$$

## 局限性

- 基本采样法无法实现对累积分布函数及其逆函数难以求解的目标分布进行采样。
- 示例：标准正态分布 $p(y)=\frac{1}{\sqrt{2 \pi}} e^{-y^{2}/2}$，其累积分布函数为：
$$\begin{aligned} h(y) & =\int_{-\infty}^{y} \frac{1}{\sqrt{2 \pi}} e^{-y^{2}/2} d y \\ & =\frac{1}{2}+\frac{1}{2} erf\left(\frac{y}{\sqrt{2}}\right) \end{aligned}$$
  其中 $erf(y)=\frac{2}{\sqrt{\pi}} \int_{0}^{y} e^{-t^{2}} d t$ 为高斯误差函数，无法求出其逆函数，因此不适用于基本采样法直接采样。

# 12.3 拒绝采样法

## 思想

- 拒绝采样法 (Rejection Sampling) 利用易采样的分布，通过接受-拒绝的思想来近似目标分布，避免了基本采样法所需的累积分布函数及其逆函数的求解。
- 核心思路：
  1. 设目标分布的概率密度函数为 $p(z)$，借助一个容易采样的分布 $q(z)$ 去逼近 $p(z)$，$q(z)$ 称为建议分布；
  2. 从 $q(z)$ 中采集产生点 $(z_{0}, u_{0})$；
  3. 若 $u_{0}<\frac{p(z_{0})}{k q(z_{0})}$，则返回采样点 $z_{0}$，否则拒绝采样点。

## 关键问题：建议分布

- 建议分布需满足的条件：
  1. 建议分布应覆盖目标分布的样本集，以确保能够生成符合目标的样本；
  2. 建议分布的形状应与目标分布相似并尽可能逼近目标。
- 为实现上述要求，需找到一个常数 $k$，使得对任意的 $z$ 有：
$$\frac{p(z)}{q(z)} \leq k$$
此时，$k q(z)$ 称作对比函数。

## 算法流程

1. 确定目标分布 $p(z)$ 和易于采样的建议分布 $q(z)$，并找到满足条件的常数 $k$；
2. 从建议分布 $q(z)$ 中采样得到样本 $z_{0}$；
3. 从均匀分布 $U(0, k q(z_{0}))$ 中采样得到 $u_{0}$；
4. 若 $u_{0} < p(z_{0})$，则接受样本 $z_{0}$；否则拒绝该样本；
5. 重复步骤2-4，直到采集到足够数量的有效样本。

## 接受概率

- 采样点被接受的概率为：
$$p(accept)=\int \frac{p(z)}{k q(z)} q(z) d z=\frac{1}{k} \int p(z) d z$$

## 局限性

- 当接受率较低时，导致被拒绝的样本较多，从而导致采样效率较低；
- 对于高维的复杂分布 $p(z_{1}, z_{2}, ..., z_{n})$，找到合适的建议分布 $q(z)$ 和 $k$ 非常困难；
- 对于高维的复杂分布，若只能得到条件分布 $p(z_{n-1} | z_{n})$，但无法得到高维分布的联合概率分布，则无法采用拒绝采样法。

# 12.4 重要性采样

## 基本思想

- 重要性采样 (Importance Sampling) 与拒绝采样类似，使用一个易于抽样的建议分布来代替目标分布，通过加权的方式调整样本，使其反映目标分布的特性，近似目标分布。
- 核心公式：
$$\mathbb{E}(f)=\int f(z) p(z) d z=\int f(z) \frac{p(z)}{q(z)} q(z) d z \simeq \frac{1}{L} \sum_{l=1}^{L}\left[\frac{p\left(z^{(l)}\right)}{q\left(z^{(l)}\right)}\right] f\left(z^{(l)}\right)$$
- 关键说明：引入易于抽取样本的建议分布 $q(z)$，可将期望表示为从 $q(z)$ 中抽取的样本集合 $\{z^{(l)}\}$ 的有限和形式，重要性权重 $\frac{p(z^{(l)})}{q(z^{(l)})}$ 矫正了从错误分布中采样而引入的偏差。

## 适用场景

- 用于在概率模型中估计某些难以直接计算的期望值。
- 特别适用于当目标分布难以直接从中抽样，或者抽样成本非常高时。
- 期望估计的基础形式：对于变量 $z \sim p(z)$，关于 $z$ 的函数 $f(z)$，其期望为：
$$\mathbb{E}(f)=\int f(z) p(z) d z \Rightarrow \mathbb{E}(f) \simeq \frac{1}{L} \sum_{l=1}^{L} f\left(z^{(l)}\right)$$
该形式依赖于能够从分布 $p(z)$ 中抽样，不具有普适性。

## 算法流程

1. 确定目标分布 $p(z)$ 和易于采样的建议分布 $q(z)$；
2. 从建议分布 $q(z)$ 中独立抽取 $L$ 个样本 $z^{(1)}, z^{(2)}, ..., z^{(L)}$；
3. 计算每个样本对应的重要性权重 $w^{(l)} = \frac{p(z^{(l)})}{q(z^{(l)})}$；
4. 目标函数的期望近似为加权和：
$$\mathbb{E}(f) \simeq \frac{1}{L} \sum_{l=1}^{L} w^{(l)} f(z^{(l)})$$

## 更一般场景（概率分布未归一化）

- 若目标分布未归一化：$p(z)=\frac{\tilde{p}(z)}{Z_{p}}$，其中 $\tilde{p}(z)$ 已知，$Z_{p}$ 为未知归一化常量；
- 建议分布 $q(z)=\frac{\tilde{q}(z)}{Z_{q}}$，其中 $\tilde{q}(z)$ 已知，$Z_{q}$ 为建议分布的归一化常量；
- 期望推导：
$$\mathbb{E}(f)=\int f(z) p(z) d z=\frac{Z_{q}}{Z_{p}} \int f(z) \frac{\tilde{p}(z)}{\tilde{q}(z)} q(z) d z \simeq \frac{Z_{q}}{Z_{p}} \frac{1}{L} \sum_{l=1}^{L} \frac{\tilde{p}\left(z^{(l)}\right)}{\tilde{q}\left(z^{(l)}\right)} f\left(z^{(l)}\right)$$
- 归一化常量比值计算：
$$\frac{Z_{p}}{Z_{q}}=\frac{1}{Z_{q}} \int \tilde{p}(z) d z=\int \frac{\tilde{p}(z)}{\tilde{q}(z)} q(z) d z \simeq \frac{1}{L} \sum_{l=1}^{L} \frac{\tilde{p}\left(z^{(l)}\right)}{\tilde{q}\left(z^{(l)}\right)}$$
- 最终期望近似：
$$\mathbb{E}(f) \simeq \sum_{l=1}^{L} w_{l} f\left(z^{(l)}\right)$$
其中归一化权重：
$$w_{l}=\frac{\tilde{p}\left(z^{(l)}\right) / q\left(z^{(l)}\right)}{\sum_{m=1}^{L} \tilde{p}\left(z^{(m)}\right) / q\left(z^{(m)}\right)}$$

## 特点总结

- 可用于多种复杂度的分布估计，尤其是难以直接抽样的情况；
- 相较于简单随机采样效率更高；
- 建议分布与目标分布差异较大时，会导致估计的方差很大，估计变得不稳定。

# 12.5 马尔可夫蒙特卡罗采样

## 马尔可夫蒙特卡罗法 (Markov Chain Monte Carlo, MCMC)

- 定义：是一种从复杂概率分布中采集样本的方法。
- 核心特点：不同于拒绝采样法需选取适当的建议分布，MCMC利用马尔可夫链的收敛性质，通过迭代生成样本，并最终收敛到目标分布。
- 适用场景：在高维的联合概率分布难以求解时，仅需知道目标分布对应的各维间的条件概率分布，也可利用MCMC采样进行求解（基本采样法和拒绝采样法均不适用）。
- 关键问题：马尔可夫链的构造。
- 起源背景：蒙特卡罗方法于20世纪40年代“曼哈顿计划”成员S.M.乌拉姆和J.冯·诺伊曼首先提出，1777年法国Buffon的投针实验是其早期实例。

## 马尔可夫链

### 回顾：马尔可夫链的定义与性质

- 一阶马尔可夫链(First Order Markov Chain)：
$$p\left(z^{m+1} | z^{1}, ..., z^{m}\right)=p\left(z^{m+1} | z^{m}\right)$$
- 高阶马尔可夫链(High Order Markov Chain)：
$$p\left(z^{m+1}|z^{1},... ,z^{m}\right) =p\left(z^{m+1}|z^{m},... ,z^{m-n}\right)$$
- 转移概率(Transition Probabilities)：
$$T\left(z^{m}, z^{m+1}\right) \equiv p\left(z^{m+1} | z^{m}\right)$$
- 转移概率矩阵：
$$T=\left[\begin{array}{cccc} T(1,1), & T(1,2), & ... & T(1, m) \\ T(2,1), & T(2,2), & ... & T(2, m) \\ & \vdots & \ddots & \vdots \\ T(m, 1), & T(m, 2), & ... & T(m, m) \end{array}\right]$$

### 收敛性质

当 $m \to \infty$ 时，马尔可夫链各状态趋近于平稳，即：
$$p_{m}=p_{m-1} \stackrel{m \to \infty}{\to } p=p T$$
其中 $p=[p(1), ..., p(j)]$ 为平稳分布，且有：
$$lim _{m \to \infty} T^{m}=\left[\begin{array}{c} p(1), ..., p(j), ... \\ ... \\ p(1), ..., p(j), ... \end{array}\right]$$

## 细致平稳-充分条件

- 定义：若马尔可夫链的状态转移矩阵 $T$ 和概率分布 $p(z)$ 对所有的 $i, j$ 满足：
$$p(i) T(i, j)=p(j) T(j, i)$$
则称概率分布 $p(z)$ 是状态转移矩阵 $T$ 的平稳分布。

## MCMC采样法的思想与步骤

### 核心思想

对于需采样的目标分布 $p(z)$，构造转移矩阵为 $T$ 的马尔可夫链，使它的平稳分布恰好为 $p(z)$。

### 采样步骤

1. 从任意简单概率分布中采样初始状态；
2. 利用目标平稳分布对应的状态转移矩阵 $T$ 构造马尔可夫链；
3. 迭代至一定次数后，达到平稳分布对应的样本集即为采样结果。

## Metropolis-Hastings方法

### 核心思想

一般情况下，目标平稳分布 $p(z)$ 和某个马尔可夫链转移矩阵 $T'$ 不满足细致平稳条件（即 $p(i)T'(i,j)\neq p(j)T'(j,i)$），引入接受率 $\alpha(i, j)$ 使：
$$p(i) T'(i, j) \alpha(i, j)=p(j) T'(j, i) \alpha(j, i)$$
令：
$$\begin{aligned} & \alpha(i, j)=p(j) T(j, i) \\ & \alpha(j, i)=p(i) T(i, j) \end{aligned}$$
此时平稳分布对应转移矩阵为：
$$T(i, j)=T'(i, j) \alpha(i, j)$$
即从状态 $i$ 以 $T'(i, j)$ 转移到状态 $j$ 时，以 $\alpha(i, j)$ 的概率接受这个转移。

### 接受率优化

为提高采样效率，同比例放大接受率，使最大接受率为1，令：
$$A(i, j)=min \left\{1, \frac{p(j) T(j, i)}{p(i) T(i, j)}\right\}$$
用 $A(i, j)$ 替换原接受率 $\alpha(i, j)$。

### 算法流程

1. 初始化：从任意状态 $z^{(0)}$ 开始，设置迭代次数 $N$ 和burn-in期（丢弃初始不稳定样本的时期）；
2. 迭代采样：
   - 对每个迭代步 $t=1,2,...,N$，从建议分布 $T'(z^{(t-1)}, \cdot)$ 中采样候选状态 $z^*$；
   - 计算接受率 $A(z^{(t-1)}, z^*)=min\left\{1, \frac{p(z^*) T'(z^*, z^{(t-1)})}{p(z^{(t-1)}) T'(z^{(t-1)}, z^*)}\right\}$；
   - 从均匀分布 $U(0,1)$ 中采样 $u$，若 $u < A(z^{(t-1)}, z^*)$，则接受候选状态 $z^{(t)}=z^*$，否则保留原状态 $z^{(t)}=z^{(t-1)}$；
3. 输出结果：丢弃burn-in期样本，剩余样本即为目标分布的近似样本。

### 局限性

- 接受率计算式 $\frac{p(j) T(j, i)}{p(i) T(i, j)}$ 在高维时计算量较大，导致算法效率较低；
- 接受率一般小于1，进一步降低采样效率；
- 高维场景下难以求出各特征维度的联合分布。

## 吉布斯采样 (Gibbs Sampling)

### 核心思想

重新寻找细致平稳条件，无需拒绝状态转移，接受率为1，是M-H采样的特殊形式。
- 对于二元分布 $p(x, y)$，若两个状态为 $(x_{1}, y_{1})$ 和 $(x_{1}, y_{2})$，则：
$$p(x_{1},y_{1})\cdot p(y_{2}|x_{1}) =p(x_{1},y_{2})\cdot p(y_{1}|x_{1})$$
满足细致平稳条件，可采用 $p(y_{2} | x_{1})$ 作为状态转移概率进行采样。
- 多维场景：每次只改变一个维度的值，保持其他维度不变，基于各维度的条件概率分布进行采样。

### 二维Gibbs采样算法流程

1. 初始化：设置采样次数 $N$、burn-in期，随机初始化初始状态 $(x^{(0)}, y^{(0)})$；
2. 迭代采样：
   - 对每个迭代步 $t=1,2,...,N$，从条件分布 $p(x | y^{(t-1)})$ 中采样 $x^{(t)}$；
   - 从条件分布 $p(y | x^{(t)})$ 中采样 $y^{(t)}$；
3. 输出结果：丢弃burn-in期样本，剩余 $\{(x^{(t)}, y^{(t)})\}$ 即为目标分布的近似样本。

### 多维Gibbs采样算法

每次仅更新一个维度，其他维度保持不变，依次循环更新所有维度，直至完成所有迭代。

## 马尔可夫蒙特卡洛采样法小结

- MCMC是基于马尔可夫链进行采样的一类方法；
- Metropolis-Hasting (M-H) 是MCMC的特定实现，通过引入接受率构造状态转移概率，生成下一个状态；
- 吉布斯方法是M-H方法的特例，无需知道高维联合分布，仅需各维度间的条件概率分布，且接受率为1，采样效率更高。

# 12.6 采样方法总结

![](sampling_methods.png)